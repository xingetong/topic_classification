{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21e21f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc30fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\joblib\\backports.py:22: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils  # noqa\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\utils\\multiclass.py:14: DeprecationWarning: Please use `spmatrix` from the `scipy.sparse` namespace, the `scipy.sparse.base` namespace is deprecated.\n",
      "  from scipy.sparse.base import spmatrix\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\utils\\optimize.py:18: DeprecationWarning: Please use `line_search_wolfe2` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\n",
      "  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\utils\\optimize.py:18: DeprecationWarning: Please use `line_search_wolfe1` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\n",
      "  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942c5ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: DeprecationWarning: invalid escape sequence '\\P'\n",
      "<>:1: DeprecationWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\researcher\\AppData\\Local\\Temp\\ipykernel_7976\\1017671776.py:1: DeprecationWarning: invalid escape sequence '\\P'\n",
      "  df = pd.read_csv('D:\\Projects\\Jupyter\\Github Docs\\datasets\\preprocessed_word_correct_token.csv', encoding='utf-8')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>sentence</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "      <th>readability</th>\n",
       "      <th>preprocessed_reviews</th>\n",
       "      <th>wordtoken</th>\n",
       "      <th>correctmapping</th>\n",
       "      <th>ngrams_reviews</th>\n",
       "      <th>ngrams_token</th>\n",
       "      <th>lda_reviews</th>\n",
       "      <th>lda_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275850</td>\n",
       "      <td>1</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.6</td>\n",
       "      <td>this be my review prior to the update nothis g...</td>\n",
       "      <td>['this', 'be', 'my', 'review', 'prior', 'to', ...</td>\n",
       "      <td>['this', 'be', 'my', 'review', 'prior', 'to', ...</td>\n",
       "      <td>this be my review prior to the update nothin g...</td>\n",
       "      <td>['review', 'prior', 'update', 'nothin', 'fail'...</td>\n",
       "      <td>review prior update nothin fail miserably anno...</td>\n",
       "      <td>['review', 'prior', 'update', 'nothin', 'fail'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275850</td>\n",
       "      <td>2</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>When the game first came out it had over 200,0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>when the game first come out it have over play...</td>\n",
       "      <td>['when', 'the', 'game', 'first', 'come', 'out'...</td>\n",
       "      <td>['when', 'the', 'game', 'first', 'come', 'out'...</td>\n",
       "      <td>when the game first come out it have over play...</td>\n",
       "      <td>['first', 'player', 'one', 'point', 'mear']</td>\n",
       "      <td>first come player one point mear</td>\n",
       "      <td>['first', 'player', 'one', 'point', 'mear']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275850</td>\n",
       "      <td>3</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>If that doesn't prove this game is the biggest...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>if that do not prove this game be the big scam...</td>\n",
       "      <td>['if', 'that', 'do', 'not', 'prove', 'this', '...</td>\n",
       "      <td>['if', 'that', 'do', 'not', 'prove', 'this', '...</td>\n",
       "      <td>if that do not prove this game be the big scam...</td>\n",
       "      <td>['prove', 'this_game', 'big', 'scam', 'know']</td>\n",
       "      <td>prove big scam know</td>\n",
       "      <td>['prove', 'big', 'scam', 'know']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275850</td>\n",
       "      <td>4</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>The devs completely lied about countless featu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>the developer completely lie about countless f...</td>\n",
       "      <td>['the', 'developer', 'completely', 'lie', 'abo...</td>\n",
       "      <td>['the', 'developer', 'completely', 'lie', 'abo...</td>\n",
       "      <td>the developer completely lie about countless f...</td>\n",
       "      <td>['the_developer', 'completely', 'lie_about', '...</td>\n",
       "      <td>developer completely lie countless feature meant</td>\n",
       "      <td>['developer', 'completely', 'lie', 'countless'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275850</td>\n",
       "      <td>5</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>______________________________________________...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1</td>\n",
       "      <td>i clearly have very strong feel about the game...</td>\n",
       "      <td>['clearly', 'have', 'very', 'strong', 'feel', ...</td>\n",
       "      <td>['clearly', 'have', 'very', 'strong', 'feel', ...</td>\n",
       "      <td>clearly have very strong feel about the game a...</td>\n",
       "      <td>['clearly', 'strong', 'feel', 'play', 'hour', ...</td>\n",
       "      <td>clearly strong feel play hour hello games rele...</td>\n",
       "      <td>['clearly', 'strong', 'feel', 'play_hour', 'he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  index          name  \\\n",
       "0  275850      1  No Man's Sky   \n",
       "1  275850      2  No Man's Sky   \n",
       "2  275850      3  No Man's Sky   \n",
       "3  275850      4  No Man's Sky   \n",
       "4  275850      5  No Man's Sky   \n",
       "\n",
       "                                             content  \\\n",
       "0  This was my review prior to the 1.1 update ___...   \n",
       "1  This was my review prior to the 1.1 update ___...   \n",
       "2  This was my review prior to the 1.1 update ___...   \n",
       "3  This was my review prior to the 1.1 update ___...   \n",
       "4  This was my review prior to the 1.1 update ___...   \n",
       "\n",
       "                                            sentence  review_score  \\\n",
       "0  This was my review prior to the 1.1 update ___...             1   \n",
       "1  When the game first came out it had over 200,0...             1   \n",
       "2  If that doesn't prove this game is the biggest...             1   \n",
       "3  The devs completely lied about countless featu...             1   \n",
       "4  ______________________________________________...             1   \n",
       "\n",
       "   review_votes  readability  \\\n",
       "0             1         17.6   \n",
       "1             1          6.5   \n",
       "2             1          5.6   \n",
       "3             1          8.7   \n",
       "4             1         29.1   \n",
       "\n",
       "                                preprocessed_reviews  \\\n",
       "0  this be my review prior to the update nothis g...   \n",
       "1  when the game first come out it have over play...   \n",
       "2  if that do not prove this game be the big scam...   \n",
       "3  the developer completely lie about countless f...   \n",
       "4  i clearly have very strong feel about the game...   \n",
       "\n",
       "                                           wordtoken  \\\n",
       "0  ['this', 'be', 'my', 'review', 'prior', 'to', ...   \n",
       "1  ['when', 'the', 'game', 'first', 'come', 'out'...   \n",
       "2  ['if', 'that', 'do', 'not', 'prove', 'this', '...   \n",
       "3  ['the', 'developer', 'completely', 'lie', 'abo...   \n",
       "4  ['clearly', 'have', 'very', 'strong', 'feel', ...   \n",
       "\n",
       "                                      correctmapping  \\\n",
       "0  ['this', 'be', 'my', 'review', 'prior', 'to', ...   \n",
       "1  ['when', 'the', 'game', 'first', 'come', 'out'...   \n",
       "2  ['if', 'that', 'do', 'not', 'prove', 'this', '...   \n",
       "3  ['the', 'developer', 'completely', 'lie', 'abo...   \n",
       "4  ['clearly', 'have', 'very', 'strong', 'feel', ...   \n",
       "\n",
       "                                      ngrams_reviews  \\\n",
       "0  this be my review prior to the update nothin g...   \n",
       "1  when the game first come out it have over play...   \n",
       "2  if that do not prove this game be the big scam...   \n",
       "3  the developer completely lie about countless f...   \n",
       "4  clearly have very strong feel about the game a...   \n",
       "\n",
       "                                        ngrams_token  \\\n",
       "0  ['review', 'prior', 'update', 'nothin', 'fail'...   \n",
       "1        ['first', 'player', 'one', 'point', 'mear']   \n",
       "2      ['prove', 'this_game', 'big', 'scam', 'know']   \n",
       "3  ['the_developer', 'completely', 'lie_about', '...   \n",
       "4  ['clearly', 'strong', 'feel', 'play', 'hour', ...   \n",
       "\n",
       "                                         lda_reviews  \\\n",
       "0  review prior update nothin fail miserably anno...   \n",
       "1                   first come player one point mear   \n",
       "2                                prove big scam know   \n",
       "3   developer completely lie countless feature meant   \n",
       "4  clearly strong feel play hour hello games rele...   \n",
       "\n",
       "                                           lda_token  \n",
       "0  ['review', 'prior', 'update', 'nothin', 'fail'...  \n",
       "1        ['first', 'player', 'one', 'point', 'mear']  \n",
       "2                   ['prove', 'big', 'scam', 'know']  \n",
       "3  ['developer', 'completely', 'lie', 'countless'...  \n",
       "4  ['clearly', 'strong', 'feel', 'play_hour', 'he...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\Projects\\Jupyter\\Github Docs\\datasets\\preprocessed_word_correct_token.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796fbe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eec6081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clearly',\n",
       " 'strong',\n",
       " 'feel',\n",
       " 'play_hour',\n",
       " 'hello_games',\n",
       " 'release',\n",
       " 'new',\n",
       " 'update',\n",
       " 'decide',\n",
       " 'need',\n",
       " 'resist',\n",
       " 'order',\n",
       " 'see',\n",
       " 'sort',\n",
       " 'improvement']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(df['lda_token'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc33a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(s):\n",
    "    s = eval(s)\n",
    "    s = ' '.join(s)\n",
    "    return s\n",
    "df['lda_token'] = df['lda_token'].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e73c6575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review prior update nothin fail miserably annoyed stuck garbage library completely terrible likely never play',\n",
       " 'first player one point mear',\n",
       " 'prove big scam know']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.lda_token.values.tolist()\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e25a0b",
   "metadata": {},
   "source": [
    "# Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e1d466",
   "metadata": {},
   "source": [
    "## TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba16937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 99.4 ms\n",
      "(500, 1405)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "                                 max_df=500, \n",
    "                                   max_features=2000,\n",
    "                                 min_df=0, \n",
    "#                                  stop_words='english',\n",
    "                                   use_idf=True, \n",
    "#                                    token_pattern='[a-zA-Z0-9]{3,}', \n",
    "#                                    ngram_range=(1,3)\n",
    ")\n",
    "\n",
    "%time tfidf_vectorized = tfidf_vectorizer.fit_transform(data)\n",
    "\n",
    "print(tfidf_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "804f4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data_vectorized = tfidf_vectorizer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "411d27a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa',\n",
       " 'abandon',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'absent',\n",
       " 'absolutely',\n",
       " 'abstract',\n",
       " 'accept',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'across',\n",
       " 'action',\n",
       " 'active',\n",
       " 'activism',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'adversity',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'af',\n",
       " 'afterward',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aimless',\n",
       " 'air',\n",
       " 'algorithm',\n",
       " 'aliasing',\n",
       " 'alien',\n",
       " 'alive',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alpha',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alternate',\n",
       " 'although',\n",
       " 'always',\n",
       " 'amain',\n",
       " 'amaze',\n",
       " 'ambitious',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'animal',\n",
       " 'anisotropic',\n",
       " 'annoy',\n",
       " 'annoyed',\n",
       " 'another',\n",
       " 'anti',\n",
       " 'anticipate',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anything_like',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apparent',\n",
       " 'appeal',\n",
       " 'appreciate',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'argument',\n",
       " 'armourer',\n",
       " 'around',\n",
       " 'arrive',\n",
       " 'art',\n",
       " 'artstyle',\n",
       " 'artsy',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'aspect',\n",
       " 'assumption',\n",
       " 'atlas',\n",
       " 'atom',\n",
       " 'attack',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awsome',\n",
       " 'back',\n",
       " 'backwards',\n",
       " 'bad',\n",
       " 'band',\n",
       " 'bare',\n",
       " 'base',\n",
       " 'base_building',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'battle',\n",
       " 'battlefield',\n",
       " 'bay',\n",
       " 'beacon',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'beforehand',\n",
       " 'begin',\n",
       " 'behind',\n",
       " 'believe',\n",
       " 'belong',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'beta',\n",
       " 'bias',\n",
       " 'big',\n",
       " 'biggie',\n",
       " 'biome',\n",
       " 'bit',\n",
       " 'black',\n",
       " 'blast',\n",
       " 'bldr',\n",
       " 'blinder',\n",
       " 'blown',\n",
       " 'blueprint',\n",
       " 'blur',\n",
       " 'bone',\n",
       " 'book',\n",
       " 'boring',\n",
       " 'bought',\n",
       " 'break',\n",
       " 'breaker',\n",
       " 'breathtaking',\n",
       " 'brilliant',\n",
       " 'brilliantly',\n",
       " 'bring',\n",
       " 'brings',\n",
       " 'broadens',\n",
       " 'broken',\n",
       " 'brought',\n",
       " 'bubble',\n",
       " 'buck',\n",
       " 'buckle',\n",
       " 'budget',\n",
       " 'bug',\n",
       " 'bugged',\n",
       " 'buggy',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bunch',\n",
       " 'bush',\n",
       " 'busy',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'buzz',\n",
       " 'bystander',\n",
       " 'call',\n",
       " 'capability',\n",
       " 'capable',\n",
       " 'capital',\n",
       " 'capture',\n",
       " 'carbon',\n",
       " 'care',\n",
       " 'cargo',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'catalogue',\n",
       " 'cause',\n",
       " 'cave',\n",
       " 'cell',\n",
       " 'center',\n",
       " 'center_galaxy',\n",
       " 'center_universe',\n",
       " 'centre',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'challenge',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'charge',\n",
       " 'cheaper',\n",
       " 'check',\n",
       " 'childhood',\n",
       " 'chill',\n",
       " 'choose',\n",
       " 'claim',\n",
       " 'clarify',\n",
       " 'clearly',\n",
       " 'cleary',\n",
       " 'close',\n",
       " 'closely',\n",
       " 'closer',\n",
       " 'closing',\n",
       " 'co',\n",
       " 'codenamed',\n",
       " 'collect',\n",
       " 'collection',\n",
       " 'comb',\n",
       " 'combat',\n",
       " 'comeback',\n",
       " 'comet',\n",
       " 'comment',\n",
       " 'commitment',\n",
       " 'communicate',\n",
       " 'community',\n",
       " 'compare',\n",
       " 'compel',\n",
       " 'complain',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complexity',\n",
       " 'comprehensive',\n",
       " 'compulsion',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concrete',\n",
       " 'conditional',\n",
       " 'confidence',\n",
       " 'confirmation',\n",
       " 'consequence',\n",
       " 'considerably',\n",
       " 'consists',\n",
       " 'constantly',\n",
       " 'constraint',\n",
       " 'constructive',\n",
       " 'contemplative',\n",
       " 'content',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'controversy',\n",
       " 'cool',\n",
       " 'cordite',\n",
       " 'corner',\n",
       " 'cosmetic',\n",
       " 'cost',\n",
       " 'costly',\n",
       " 'cough',\n",
       " 'could',\n",
       " 'countless',\n",
       " 'coupon',\n",
       " 'course',\n",
       " 'cover',\n",
       " 'craft',\n",
       " 'cranny',\n",
       " 'crap',\n",
       " 'crash',\n",
       " 'crazy',\n",
       " 'creative',\n",
       " 'creature',\n",
       " 'criticism',\n",
       " 'critism',\n",
       " 'crush',\n",
       " 'crushingly',\n",
       " 'cup',\n",
       " 'curious',\n",
       " 'currency',\n",
       " 'current',\n",
       " 'current_state',\n",
       " 'currently',\n",
       " 'curve',\n",
       " 'customize',\n",
       " 'cut',\n",
       " 'danger',\n",
       " 'dangerous',\n",
       " 'day',\n",
       " 'deal',\n",
       " 'death',\n",
       " 'decent',\n",
       " 'decentralize',\n",
       " 'decide',\n",
       " 'decision',\n",
       " 'decoration',\n",
       " 'deep',\n",
       " 'defense',\n",
       " 'definite',\n",
       " 'definitely',\n",
       " 'degrees',\n",
       " 'delete',\n",
       " 'deliver',\n",
       " 'demonstrate',\n",
       " 'depth',\n",
       " 'describe',\n",
       " 'deserves',\n",
       " 'design',\n",
       " 'desktop',\n",
       " 'destiny',\n",
       " 'detailed',\n",
       " 'develop',\n",
       " 'developed',\n",
       " 'developer',\n",
       " 'developers',\n",
       " 'development',\n",
       " 'die',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'different_planet',\n",
       " 'dinosaur',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'disappoint',\n",
       " 'disappointed',\n",
       " 'discount',\n",
       " 'discover',\n",
       " 'discus',\n",
       " 'discuss',\n",
       " 'discussion',\n",
       " 'disliked',\n",
       " 'distance',\n",
       " 'diverse',\n",
       " 'diversity',\n",
       " 'dollar',\n",
       " 'door',\n",
       " 'dose',\n",
       " 'double',\n",
       " 'doubt',\n",
       " 'downloadable_content',\n",
       " 'dozen',\n",
       " 'dragon',\n",
       " 'drama',\n",
       " 'drawback',\n",
       " 'dream',\n",
       " 'drive',\n",
       " 'driven',\n",
       " 'drop',\n",
       " 'due',\n",
       " 'early',\n",
       " 'early_access',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'edge',\n",
       " 'edit',\n",
       " 'education',\n",
       " 'educational',\n",
       " 'effect',\n",
       " 'effort',\n",
       " 'either',\n",
       " 'elaborate',\n",
       " 'element',\n",
       " 'elite',\n",
       " 'emotion',\n",
       " 'empty',\n",
       " 'end',\n",
       " 'endless',\n",
       " 'enemy',\n",
       " 'energy',\n",
       " 'engine',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'enjoyment',\n",
       " 'enough',\n",
       " 'entertain',\n",
       " 'entice',\n",
       " 'entire',\n",
       " 'entirely',\n",
       " 'enviroment',\n",
       " 'environment',\n",
       " 'equipment',\n",
       " 'ericetal',\n",
       " 'error',\n",
       " 'especially',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'eventually',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everything_like',\n",
       " 'evolve',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'excite',\n",
       " 'excuse',\n",
       " 'exhaust',\n",
       " 'exist',\n",
       " 'exists',\n",
       " 'exosuite',\n",
       " 'expand',\n",
       " 'expandable',\n",
       " 'expansion',\n",
       " 'expect',\n",
       " 'expectation',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'explain',\n",
       " 'explains',\n",
       " 'explicitly',\n",
       " 'explode',\n",
       " 'exploration',\n",
       " 'exploration_survival',\n",
       " 'explore',\n",
       " 'explore_planet_look',\n",
       " 'explorer',\n",
       " 'extreme',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'eyed',\n",
       " 'fabled',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'fail',\n",
       " 'fair',\n",
       " 'fall',\n",
       " 'false_advertising',\n",
       " 'familiar',\n",
       " 'family',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'farm',\n",
       " 'farmer',\n",
       " 'fashion',\n",
       " 'fast',\n",
       " 'faster',\n",
       " 'fate',\n",
       " 'fear',\n",
       " 'feature',\n",
       " 'featureless',\n",
       " 'feel',\n",
       " 'feel_like',\n",
       " 'feinleib',\n",
       " 'fell',\n",
       " 'fellow',\n",
       " 'felt',\n",
       " 'fest',\n",
       " 'fiery',\n",
       " 'fifteen',\n",
       " 'fill',\n",
       " 'filter',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'first',\n",
       " 'first_hour',\n",
       " 'fix',\n",
       " 'flak',\n",
       " 'flaw',\n",
       " 'flesh',\n",
       " 'flight',\n",
       " 'fly',\n",
       " 'fly_around',\n",
       " 'focus',\n",
       " 'follow',\n",
       " 'foot',\n",
       " 'footage',\n",
       " 'force',\n",
       " 'forget',\n",
       " 'forgive',\n",
       " 'forth',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'foundation',\n",
       " 'foundation_update',\n",
       " 'fps',\n",
       " 'fps_drop',\n",
       " 'frame_rate',\n",
       " 'freak',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'freeze',\n",
       " 'freighter',\n",
       " 'freighters',\n",
       " 'frequently',\n",
       " 'friend',\n",
       " 'frigate',\n",
       " 'frst',\n",
       " 'frustration',\n",
       " 'fuel',\n",
       " 'fulfil',\n",
       " 'full',\n",
       " 'full_price',\n",
       " 'fully',\n",
       " 'fun',\n",
       " 'fun_play',\n",
       " 'furthermore',\n",
       " 'futile',\n",
       " 'future',\n",
       " 'future_update',\n",
       " 'gain',\n",
       " 'galaxy',\n",
       " 'galeodes',\n",
       " 'gameplay',\n",
       " 'garbage',\n",
       " 'gargantuan',\n",
       " 'gather',\n",
       " 'gathering',\n",
       " 'gauntlet',\n",
       " 'gb_ram',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'generate',\n",
       " 'generation',\n",
       " 'generator',\n",
       " 'genuinely',\n",
       " 'get',\n",
       " 'get_center_universe',\n",
       " 'get_refund',\n",
       " 'get_well',\n",
       " 'give',\n",
       " 'glitching',\n",
       " 'go',\n",
       " 'goal',\n",
       " 'god',\n",
       " 'gold',\n",
       " 'good',\n",
       " 'gorge',\n",
       " 'gotten',\n",
       " 'grab',\n",
       " 'grand',\n",
       " 'graphic',\n",
       " 'graphical',\n",
       " 'graphically',\n",
       " 'great',\n",
       " 'greatly',\n",
       " 'greedy',\n",
       " 'grid',\n",
       " 'grind',\n",
       " 'grindy',\n",
       " 'gripped',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'groupthink',\n",
       " 'gtx',\n",
       " 'guaranteed',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'haha',\n",
       " 'hail',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'hang',\n",
       " 'hanger',\n",
       " 'happen',\n",
       " 'happens',\n",
       " 'happier',\n",
       " 'hard',\n",
       " 'harder',\n",
       " 'hardly',\n",
       " 'harrow',\n",
       " 'harsh',\n",
       " 'harsher',\n",
       " 'harshly',\n",
       " 'harvest',\n",
       " 'harvesting',\n",
       " 'hat',\n",
       " 'hate',\n",
       " 'haul',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'hearing',\n",
       " 'heart',\n",
       " 'held',\n",
       " 'hell',\n",
       " 'hello_games',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'hence',\n",
       " 'heredium',\n",
       " 'hey',\n",
       " 'high',\n",
       " 'highlight',\n",
       " 'highly',\n",
       " 'hilarious',\n",
       " 'hint',\n",
       " 'hire',\n",
       " 'hit',\n",
       " 'hmm',\n",
       " 'holding',\n",
       " 'hole',\n",
       " 'holy',\n",
       " 'home',\n",
       " 'homestead',\n",
       " 'honest',\n",
       " 'honestly',\n",
       " 'hooked',\n",
       " 'hop',\n",
       " 'hopeful',\n",
       " 'hopefully',\n",
       " 'horizon',\n",
       " 'horrible',\n",
       " 'horrifically',\n",
       " 'horse',\n",
       " 'hound',\n",
       " 'hour',\n",
       " 'hour_play',\n",
       " 'hour_played',\n",
       " 'hour_still',\n",
       " 'however',\n",
       " 'huge',\n",
       " 'hugely',\n",
       " 'hundred',\n",
       " 'hunt',\n",
       " 'hype',\n",
       " 'hyped',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'ideology',\n",
       " 'idiotic',\n",
       " 'ignore',\n",
       " 'illusion',\n",
       " 'immediate',\n",
       " 'immerse',\n",
       " 'immersion',\n",
       " 'important',\n",
       " 'impossible',\n",
       " 'impressed',\n",
       " 'impression',\n",
       " 'impressive',\n",
       " 'improve',\n",
       " 'improvement',\n",
       " 'improves',\n",
       " 'inability',\n",
       " 'incase',\n",
       " 'inch',\n",
       " 'inclination',\n",
       " 'include',\n",
       " 'incomplete',\n",
       " 'indeed',\n",
       " 'indictment',\n",
       " 'indie',\n",
       " 'individual',\n",
       " 'indoors',\n",
       " 'inference',\n",
       " 'inform',\n",
       " 'inital',\n",
       " 'initial',\n",
       " 'innovation',\n",
       " 'inside',\n",
       " 'instal',\n",
       " 'install',\n",
       " 'instantly',\n",
       " 'instead',\n",
       " 'instruction',\n",
       " 'insult',\n",
       " 'integrity',\n",
       " 'intel',\n",
       " 'intend',\n",
       " 'intent',\n",
       " 'interaction',\n",
       " 'interest',\n",
       " 'interested',\n",
       " 'interesting',\n",
       " 'intrigue',\n",
       " 'intro',\n",
       " 'introduce',\n",
       " 'inventory',\n",
       " 'invest',\n",
       " 'investment',\n",
       " 'invincible',\n",
       " 'irrespective',\n",
       " 'issue',\n",
       " 'item',\n",
       " 'iv',\n",
       " 'job',\n",
       " 'journey',\n",
       " 'judged',\n",
       " 'jumping',\n",
       " 'kept',\n",
       " 'key',\n",
       " 'kid',\n",
       " 'kill',\n",
       " 'kind',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'kraken',\n",
       " 'kudos',\n",
       " 'lack',\n",
       " 'laid',\n",
       " 'land',\n",
       " 'large',\n",
       " 'largely',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'launch',\n",
       " 'layer',\n",
       " 'lead',\n",
       " 'learn',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'left',\n",
       " 'less',\n",
       " 'lesson',\n",
       " 'let',\n",
       " 'level',\n",
       " 'library',\n",
       " 'lie',\n",
       " 'life',\n",
       " 'light',\n",
       " 'lightyears',\n",
       " 'like',\n",
       " 'like_exploration',\n",
       " 'like_explore',\n",
       " 'like_minecraft',\n",
       " 'like_seemingly',\n",
       " 'likely',\n",
       " 'limitation',\n",
       " 'limited',\n",
       " 'limitless',\n",
       " 'listen',\n",
       " 'literally',\n",
       " 'little',\n",
       " 'live',\n",
       " 'liven',\n",
       " 'living',\n",
       " 'load',\n",
       " 'load_screen',\n",
       " 'local',\n",
       " 'location',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'look_forward',\n",
       " 'loop',\n",
       " 'lord',\n",
       " 'lose',\n",
       " 'lot',\n",
       " 'lot_fun',\n",
       " 'lot_people',\n",
       " 'love',\n",
       " 'love_explore',\n",
       " 'lovely',\n",
       " 'lover',\n",
       " 'low',\n",
       " 'magic',\n",
       " 'main',\n",
       " 'major',\n",
       " 'majority',\n",
       " 'make_feel',\n",
       " 'make_feel_like',\n",
       " 'manage',\n",
       " 'management',\n",
       " 'manual',\n",
       " 'manufacture',\n",
       " 'many',\n",
       " 'many_hour',\n",
       " 'many_people',\n",
       " 'mar',\n",
       " 'mark',\n",
       " 'market',\n",
       " 'marketing',\n",
       " 'mass',\n",
       " 'massive',\n",
       " 'massively',\n",
       " 'material',\n",
       " 'matter',\n",
       " 'maximum',\n",
       " 'maybe',\n",
       " 'mean',\n",
       " 'meaningful',\n",
       " 'meant',\n",
       " 'mear',\n",
       " 'meat',\n",
       " 'mechanic',\n",
       " 'megatype',\n",
       " 'mellow',\n",
       " 'menu',\n",
       " 'merely',\n",
       " 'mess',\n",
       " 'message',\n",
       " 'might',\n",
       " 'mile',\n",
       " 'mileage',\n",
       " 'milk',\n",
       " 'mind',\n",
       " 'minecraft',\n",
       " 'mining',\n",
       " 'minor',\n",
       " 'minority',\n",
       " 'minute',\n",
       " 'miserably',\n",
       " 'mislead',\n",
       " 'misleading',\n",
       " 'miss',\n",
       " 'mission',\n",
       " 'mistake',\n",
       " 'mixed',\n",
       " 'mode',\n",
       " 'module',\n",
       " 'moment',\n",
       " 'money',\n",
       " 'month',\n",
       " 'monumental',\n",
       " 'moon',\n",
       " 'mostly',\n",
       " 'motion',\n",
       " 'motivate',\n",
       " 'motivator',\n",
       " 'mountain',\n",
       " 'move',\n",
       " 'movie',\n",
       " 'much',\n",
       " 'multi_tool',\n",
       " 'multiplayer',\n",
       " 'multiple',\n",
       " 'must',\n",
       " 'mystery',\n",
       " 'nature',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessity',\n",
       " 'need',\n",
       " 'negative',\n",
       " 'negative_review',\n",
       " 'negativity',\n",
       " 'network',\n",
       " 'never',\n",
       " 'new',\n",
       " 'new_planet',\n",
       " 'new_thing',\n",
       " 'newcomer',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'niche',\n",
       " 'nit',\n",
       " 'no',\n",
       " 'no_crash',\n",
       " 'no_man_sky',\n",
       " 'no_mans',\n",
       " 'no_multiplayer',\n",
       " 'no_one',\n",
       " 'no_problem',\n",
       " 'no_way',\n",
       " 'nod',\n",
       " 'nomad',\n",
       " 'non',\n",
       " 'none',\n",
       " 'nonetheless',\n",
       " 'nook',\n",
       " 'normal',\n",
       " 'note',\n",
       " 'nothin',\n",
       " 'nothing',\n",
       " 'notice',\n",
       " 'novel',\n",
       " 'nvidia',\n",
       " 'object',\n",
       " 'objective',\n",
       " 'obvious',\n",
       " 'obviously',\n",
       " 'occasionally',\n",
       " 'occasions',\n",
       " 'offer',\n",
       " 'offering',\n",
       " 'often',\n",
       " 'old',\n",
       " 'ona',\n",
       " 'one',\n",
       " 'one_planet',\n",
       " 'one_thing',\n",
       " 'online',\n",
       " 'onto',\n",
       " 'onwards',\n",
       " 'op',\n",
       " 'open',\n",
       " 'opinion',\n",
       " 'opinions',\n",
       " 'opportunity',\n",
       " 'optimize',\n",
       " 'option',\n",
       " 'order',\n",
       " 'original',\n",
       " 'others',\n",
       " 'ought',\n",
       " 'outline',\n",
       " 'overall',\n",
       " 'overblown',\n",
       " 'overcome',\n",
       " 'overhaul',\n",
       " 'overlook',\n",
       " 'overly',\n",
       " 'overprice',\n",
       " 'overreacted',\n",
       " 'pace',\n",
       " 'pack',\n",
       " 'package',\n",
       " 'packed',\n",
       " 'paid',\n",
       " 'paint',\n",
       " 'part',\n",
       " 'particular',\n",
       " 'past',\n",
       " 'patch',\n",
       " 'path',\n",
       " 'patient',\n",
       " 'pay',\n",
       " 'payed',\n",
       " 'people',\n",
       " 'per',\n",
       " 'perception',\n",
       " 'perfect',\n",
       " 'performance_issue',\n",
       " 'period',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'personal_computer',\n",
       " 'personal_computer_port',\n",
       " 'personally',\n",
       " 'pick',\n",
       " 'picture',\n",
       " 'piece',\n",
       " 'pinch',\n",
       " 'pipeline',\n",
       " 'pirate',\n",
       " 'pistol',\n",
       " 'place',\n",
       " 'placement',\n",
       " 'plan',\n",
       " 'planet',\n",
       " 'planets',\n",
       " 'plant',\n",
       " 'play',\n",
       " 'play_hour',\n",
       " 'play_no_mans',\n",
       " 'playable',\n",
       " 'played',\n",
       " 'played_hour',\n",
       " 'player',\n",
       " 'please',\n",
       " 'pleased',\n",
       " 'plenty',\n",
       " 'plus',\n",
       " 'plutonium',\n",
       " 'pocket',\n",
       " 'point',\n",
       " 'pointless',\n",
       " 'political',\n",
       " 'politics',\n",
       " 'polygon',\n",
       " 'pool',\n",
       " 'poor',\n",
       " 'populate',\n",
       " 'port',\n",
       " 'pose',\n",
       " 'position',\n",
       " 'positive',\n",
       " 'possibilities',\n",
       " 'possible',\n",
       " 'possibly',\n",
       " 'post',\n",
       " 'potential',\n",
       " 'pour',\n",
       " 'power',\n",
       " 'practically',\n",
       " 'pre',\n",
       " 'pre_ordering',\n",
       " 'predictable',\n",
       " 'prematch',\n",
       " 'present',\n",
       " 'press',\n",
       " 'pretty',\n",
       " 'previous',\n",
       " 'previously',\n",
       " 'price',\n",
       " 'price_tag',\n",
       " 'pricey',\n",
       " 'prior',\n",
       " 'priority',\n",
       " 'pro',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'procedural_generation',\n",
       " 'produce',\n",
       " 'product',\n",
       " 'production',\n",
       " 'prof',\n",
       " 'profit',\n",
       " 'progress',\n",
       " 'progression',\n",
       " 'promise',\n",
       " 'promising',\n",
       " 'prompt',\n",
       " 'proof',\n",
       " 'prop',\n",
       " 'properly',\n",
       " 'proportion',\n",
       " 'prove',\n",
       " 'provide',\n",
       " 'pull',\n",
       " 'purchasable',\n",
       " 'purchase',\n",
       " 'purely',\n",
       " 'purpose',\n",
       " 'push',\n",
       " 'put',\n",
       " 'quality',\n",
       " 'quest',\n",
       " 'questing',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a357f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data_feature_names=tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44dbd1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_Sparsicity:  0.586761565836299 %\n"
     ]
    }
   ],
   "source": [
    "tfidf_data_dense = tfidf_data_vectorized.todense()\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"tfidf_Sparsicity: \", ((tfidf_data_dense > 0).sum()/tfidf_data_dense.size)*100, \"%\")\n",
    "# Since most cells in this matrix will be zero, I am interested in knowing what percentage of cells contain non-zero values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7cea1f",
   "metadata": {},
   "source": [
    "# Build LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b61a836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(learning_method='online', n_components=20, n_jobs=-1,\n",
      "                          random_state=100)\n"
     ]
    }
   ],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=20,               # Number of topics\n",
    "                                      max_iter=10,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=128,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(tfidf_vectorized)\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "893fad79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', n_jobs=-1, random_state=100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
    "             evaluate_every=-1, learning_decay=0.7,\n",
    "             learning_method='online', learning_offset=10.0,\n",
    "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
    "             n_components=10, n_jobs=-1, perp_tol=0.1,\n",
    "             random_state=100, topic_word_prior=None,\n",
    "             total_samples=1000000.0, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "064f396c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -14809.463044918686\n",
      "Perplexity:  78934.75912888303\n",
      "{'batch_size': 128,\n",
      " 'doc_topic_prior': None,\n",
      " 'evaluate_every': -1,\n",
      " 'learning_decay': 0.7,\n",
      " 'learning_method': 'online',\n",
      " 'learning_offset': 10.0,\n",
      " 'max_doc_update_iter': 100,\n",
      " 'max_iter': 10,\n",
      " 'mean_change_tol': 0.001,\n",
      " 'n_components': 20,\n",
      " 'n_jobs': -1,\n",
      " 'perp_tol': 0.1,\n",
      " 'random_state': 100,\n",
      " 'topic_word_prior': None,\n",
      " 'total_samples': 1000000.0,\n",
      " 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(tfidf_vectorized))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(tfidf_vectorized))\n",
    "\n",
    "# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5da39cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={'max_iter': [5, 10, 15, 20, 30, 40, 50],\n",
       "                         'n_components': [5, 10, 15, 20, 25, 30, 35, 40, 45,\n",
       "                                          50]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Search Param\n",
    "search_params = {'n_components': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50], 'max_iter': [5, 10, 15, 20, 30, 40, 50]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(tfidf_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42c95480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=LatentDirichletAllocation(learning_method=None,\n",
       "                                                 n_jobs=1),\n",
       "             n_jobs=1,\n",
       "             param_grid={'max_iter': [5, 10, 15, 20, 30, 40, 50],\n",
       "                         'n_components': [5, 10, 15, 20, 25, 30, 35, 40, 45,\n",
       "                                          50]},\n",
       "             return_train_score='warn')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCV(cv=None, error_score='raise',\n",
    "       estimator=LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
    "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
    "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
    "             mean_change_tol=0.001, n_components=10, n_jobs=1,\n",
    "             perp_tol=0.1, random_state=None,\n",
    "             topic_word_prior=None, total_samples=1000000.0, verbose=0),\n",
    "        n_jobs=1,\n",
    "       param_grid={'n_components': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50], 'max_iter': [5, 10, 15, 20, 30, 40, 50]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db948a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'max_iter': 50, 'n_components': 5}\n",
      "Best Log Likelihood Score:  -3577.0264119927756\n",
      "Model Perplexity:  7553.944872666494\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(tfidf_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a7d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
