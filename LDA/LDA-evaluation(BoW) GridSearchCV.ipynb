{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21e21f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc30fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\joblib\\backports.py:22: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils  # noqa\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\utils\\multiclass.py:14: DeprecationWarning: Please use `spmatrix` from the `scipy.sparse` namespace, the `scipy.sparse.base` namespace is deprecated.\n",
      "  from scipy.sparse.base import spmatrix\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\utils\\optimize.py:18: DeprecationWarning: Please use `line_search_wolfe2` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\n",
      "  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\utils\\optimize.py:18: DeprecationWarning: Please use `line_search_wolfe1` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\n",
      "  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942c5ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: DeprecationWarning: invalid escape sequence '\\P'\n",
      "<>:1: DeprecationWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\researcher\\AppData\\Local\\Temp\\ipykernel_12928\\1017671776.py:1: DeprecationWarning: invalid escape sequence '\\P'\n",
      "  df = pd.read_csv('D:\\Projects\\Jupyter\\Github Docs\\datasets\\preprocessed_word_correct_token.csv', encoding='utf-8')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>sentence</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "      <th>readability</th>\n",
       "      <th>preprocessed_reviews</th>\n",
       "      <th>wordtoken</th>\n",
       "      <th>correctmapping</th>\n",
       "      <th>ngrams_reviews</th>\n",
       "      <th>ngrams_token</th>\n",
       "      <th>lda_reviews</th>\n",
       "      <th>lda_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275850</td>\n",
       "      <td>1</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.6</td>\n",
       "      <td>this be my review prior to the update nothis g...</td>\n",
       "      <td>['this', 'be', 'my', 'review', 'prior', 'to', ...</td>\n",
       "      <td>['this', 'be', 'my', 'review', 'prior', 'to', ...</td>\n",
       "      <td>this be my review prior to the update nothin g...</td>\n",
       "      <td>['review', 'prior', 'update', 'nothin', 'fail'...</td>\n",
       "      <td>review prior update nothin fail miserably anno...</td>\n",
       "      <td>['review', 'prior', 'update', 'nothin', 'fail'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275850</td>\n",
       "      <td>2</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>When the game first came out it had over 200,0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>when the game first come out it have over play...</td>\n",
       "      <td>['when', 'the', 'game', 'first', 'come', 'out'...</td>\n",
       "      <td>['when', 'the', 'game', 'first', 'come', 'out'...</td>\n",
       "      <td>when the game first come out it have over play...</td>\n",
       "      <td>['first', 'player', 'one', 'point', 'mear']</td>\n",
       "      <td>first come player one point mear</td>\n",
       "      <td>['first', 'player', 'one', 'point', 'mear']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275850</td>\n",
       "      <td>3</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>If that doesn't prove this game is the biggest...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>if that do not prove this game be the big scam...</td>\n",
       "      <td>['if', 'that', 'do', 'not', 'prove', 'this', '...</td>\n",
       "      <td>['if', 'that', 'do', 'not', 'prove', 'this', '...</td>\n",
       "      <td>if that do not prove this game be the big scam...</td>\n",
       "      <td>['prove', 'this_game', 'big', 'scam', 'know']</td>\n",
       "      <td>prove big scam know</td>\n",
       "      <td>['prove', 'big', 'scam', 'know']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275850</td>\n",
       "      <td>4</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>The devs completely lied about countless featu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>the developer completely lie about countless f...</td>\n",
       "      <td>['the', 'developer', 'completely', 'lie', 'abo...</td>\n",
       "      <td>['the', 'developer', 'completely', 'lie', 'abo...</td>\n",
       "      <td>the developer completely lie about countless f...</td>\n",
       "      <td>['the_developer', 'completely', 'lie_about', '...</td>\n",
       "      <td>developer completely lie countless feature meant</td>\n",
       "      <td>['developer', 'completely', 'lie', 'countless'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275850</td>\n",
       "      <td>5</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>______________________________________________...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1</td>\n",
       "      <td>i clearly have very strong feel about the game...</td>\n",
       "      <td>['clearly', 'have', 'very', 'strong', 'feel', ...</td>\n",
       "      <td>['clearly', 'have', 'very', 'strong', 'feel', ...</td>\n",
       "      <td>clearly have very strong feel about the game a...</td>\n",
       "      <td>['clearly', 'strong', 'feel', 'play', 'hour', ...</td>\n",
       "      <td>clearly strong feel play hour hello games rele...</td>\n",
       "      <td>['clearly', 'strong', 'feel', 'play_hour', 'he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  index          name  \\\n",
       "0  275850      1  No Man's Sky   \n",
       "1  275850      2  No Man's Sky   \n",
       "2  275850      3  No Man's Sky   \n",
       "3  275850      4  No Man's Sky   \n",
       "4  275850      5  No Man's Sky   \n",
       "\n",
       "                                             content  \\\n",
       "0  This was my review prior to the 1.1 update ___...   \n",
       "1  This was my review prior to the 1.1 update ___...   \n",
       "2  This was my review prior to the 1.1 update ___...   \n",
       "3  This was my review prior to the 1.1 update ___...   \n",
       "4  This was my review prior to the 1.1 update ___...   \n",
       "\n",
       "                                            sentence  review_score  \\\n",
       "0  This was my review prior to the 1.1 update ___...             1   \n",
       "1  When the game first came out it had over 200,0...             1   \n",
       "2  If that doesn't prove this game is the biggest...             1   \n",
       "3  The devs completely lied about countless featu...             1   \n",
       "4  ______________________________________________...             1   \n",
       "\n",
       "   review_votes  readability  \\\n",
       "0             1         17.6   \n",
       "1             1          6.5   \n",
       "2             1          5.6   \n",
       "3             1          8.7   \n",
       "4             1         29.1   \n",
       "\n",
       "                                preprocessed_reviews  \\\n",
       "0  this be my review prior to the update nothis g...   \n",
       "1  when the game first come out it have over play...   \n",
       "2  if that do not prove this game be the big scam...   \n",
       "3  the developer completely lie about countless f...   \n",
       "4  i clearly have very strong feel about the game...   \n",
       "\n",
       "                                           wordtoken  \\\n",
       "0  ['this', 'be', 'my', 'review', 'prior', 'to', ...   \n",
       "1  ['when', 'the', 'game', 'first', 'come', 'out'...   \n",
       "2  ['if', 'that', 'do', 'not', 'prove', 'this', '...   \n",
       "3  ['the', 'developer', 'completely', 'lie', 'abo...   \n",
       "4  ['clearly', 'have', 'very', 'strong', 'feel', ...   \n",
       "\n",
       "                                      correctmapping  \\\n",
       "0  ['this', 'be', 'my', 'review', 'prior', 'to', ...   \n",
       "1  ['when', 'the', 'game', 'first', 'come', 'out'...   \n",
       "2  ['if', 'that', 'do', 'not', 'prove', 'this', '...   \n",
       "3  ['the', 'developer', 'completely', 'lie', 'abo...   \n",
       "4  ['clearly', 'have', 'very', 'strong', 'feel', ...   \n",
       "\n",
       "                                      ngrams_reviews  \\\n",
       "0  this be my review prior to the update nothin g...   \n",
       "1  when the game first come out it have over play...   \n",
       "2  if that do not prove this game be the big scam...   \n",
       "3  the developer completely lie about countless f...   \n",
       "4  clearly have very strong feel about the game a...   \n",
       "\n",
       "                                        ngrams_token  \\\n",
       "0  ['review', 'prior', 'update', 'nothin', 'fail'...   \n",
       "1        ['first', 'player', 'one', 'point', 'mear']   \n",
       "2      ['prove', 'this_game', 'big', 'scam', 'know']   \n",
       "3  ['the_developer', 'completely', 'lie_about', '...   \n",
       "4  ['clearly', 'strong', 'feel', 'play', 'hour', ...   \n",
       "\n",
       "                                         lda_reviews  \\\n",
       "0  review prior update nothin fail miserably anno...   \n",
       "1                   first come player one point mear   \n",
       "2                                prove big scam know   \n",
       "3   developer completely lie countless feature meant   \n",
       "4  clearly strong feel play hour hello games rele...   \n",
       "\n",
       "                                           lda_token  \n",
       "0  ['review', 'prior', 'update', 'nothin', 'fail'...  \n",
       "1        ['first', 'player', 'one', 'point', 'mear']  \n",
       "2                   ['prove', 'big', 'scam', 'know']  \n",
       "3  ['developer', 'completely', 'lie', 'countless'...  \n",
       "4  ['clearly', 'strong', 'feel', 'play_hour', 'he...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\Projects\\Jupyter\\Github Docs\\datasets\\preprocessed_word_correct_token.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d70d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eec6081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clearly',\n",
       " 'strong',\n",
       " 'feel',\n",
       " 'play_hour',\n",
       " 'hello_games',\n",
       " 'release',\n",
       " 'new',\n",
       " 'update',\n",
       " 'decide',\n",
       " 'need',\n",
       " 'resist',\n",
       " 'order',\n",
       " 'see',\n",
       " 'sort',\n",
       " 'improvement']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(df['lda_token'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc33a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(s):\n",
    "    s = eval(s)\n",
    "    s = ' '.join(s)\n",
    "    return s\n",
    "df['lda_token'] = df['lda_token'].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e73c6575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review prior update nothin fail miserably annoyed stuck garbage library completely terrible likely never play',\n",
       " 'first player one point mear',\n",
       " 'prove big scam know']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.lda_token.values.tolist()\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e25a0b",
   "metadata": {},
   "source": [
    "# Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e1d466",
   "metadata": {},
   "source": [
    "## BoW vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba16937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 5.98 ms\n",
      "(500, 79)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=8,                        # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "#                              token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )\n",
    "\n",
    "%time data_vectorized = vectorizer.fit_transform(data)\n",
    "print(data_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "411d27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "804f4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature_names=vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44dbd1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsicity:  3.1063291139240508 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dense = data_vectorized.todense()\n",
    "\n",
    "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7cea1f",
   "metadata": {},
   "source": [
    "# Build LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b61a836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(learning_method='online', n_jobs=-1, random_state=100)\n"
     ]
    }
   ],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=10,               # Number of topics\n",
    "                                      max_iter=10,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=128,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "893fad79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', n_jobs=-1, random_state=100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
    "             evaluate_every=-1, learning_decay=0.7,\n",
    "             learning_method='online', learning_offset=10.0,\n",
    "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
    "             n_components=10, n_jobs=-1, perp_tol=0.1,\n",
    "             random_state=100, topic_word_prior=None,\n",
    "             total_samples=1000000.0, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "064f396c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -6373.200956072324\n",
      "Perplexity:  123.17374113848614\n",
      "{'batch_size': 128,\n",
      " 'doc_topic_prior': None,\n",
      " 'evaluate_every': -1,\n",
      " 'learning_decay': 0.7,\n",
      " 'learning_method': 'online',\n",
      " 'learning_offset': 10.0,\n",
      " 'max_doc_update_iter': 100,\n",
      " 'max_iter': 10,\n",
      " 'mean_change_tol': 0.001,\n",
      " 'n_components': 10,\n",
      " 'n_jobs': -1,\n",
      " 'perp_tol': 0.1,\n",
      " 'random_state': 100,\n",
      " 'topic_word_prior': None,\n",
      " 'total_samples': 1000000.0,\n",
      " 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
    "\n",
    "# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da39cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={'max_iter': [5, 10, 15, 20],\n",
       "                         'n_components': [5, 10, 15, 20, 25, 30, 35, 40, 45,\n",
       "                                          50]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Search Param\n",
    "search_params = {'n_components': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50], 'max_iter': [5, 10, 15, 20]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42c95480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=LatentDirichletAllocation(learning_method=None,\n",
       "                                                 n_jobs=1),\n",
       "             n_jobs=1,\n",
       "             param_grid={'max_iter': [5, 10, 15, 20],\n",
       "                         'n_components': [5, 10, 15, 20, 25, 30, 35, 40, 45,\n",
       "                                          50]},\n",
       "             return_train_score='warn')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCV(cv=None, error_score='raise',\n",
    "       estimator=LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
    "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
    "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
    "             mean_change_tol=0.001, n_components=10, n_jobs=1,\n",
    "             perp_tol=0.1, random_state=None,\n",
    "             topic_word_prior=None, total_samples=1000000.0, verbose=0),\n",
    "        n_jobs=1,\n",
    "       param_grid={'n_components': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50], 'max_iter': [5, 10, 15, 20]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db948a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'max_iter': 15, 'n_components': 5}\n",
      "Best Log Likelihood Score:  -1568.0007077544728\n",
      "Model Perplexity:  104.05514506241019\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91c8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
