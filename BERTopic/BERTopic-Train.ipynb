{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f8d284",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582070bf",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5690619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55935a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from stop_word_list import *\n",
    "from tqdm import tqdm\n",
    "import sys  \n",
    "import contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afffd314",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe13c545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>sentence</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "      <th>readability</th>\n",
       "      <th>preprocessed_reviews</th>\n",
       "      <th>wordtoken</th>\n",
       "      <th>correctmapping</th>\n",
       "      <th>ngrams_reviews</th>\n",
       "      <th>ngrams_token</th>\n",
       "      <th>lda_reviews</th>\n",
       "      <th>lda_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275850</td>\n",
       "      <td>1</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.6</td>\n",
       "      <td>this be my review prior to the update nothis g...</td>\n",
       "      <td>['this', 'be', 'my', 'review', 'prior', 'to', ...</td>\n",
       "      <td>['this', 'be', 'my', 'review', 'prior', 'to', ...</td>\n",
       "      <td>this be my review prior to the update nothin g...</td>\n",
       "      <td>['review', 'prior', 'update', 'nothin', 'fail'...</td>\n",
       "      <td>review prior update nothin fail miserably anno...</td>\n",
       "      <td>['review', 'prior', 'update', 'nothin', 'fail'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275850</td>\n",
       "      <td>2</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>When the game first came out it had over 200,0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>when the game first come out it have over play...</td>\n",
       "      <td>['when', 'the', 'game', 'first', 'come', 'out'...</td>\n",
       "      <td>['when', 'the', 'game', 'first', 'come', 'out'...</td>\n",
       "      <td>when the game first come out it have over play...</td>\n",
       "      <td>['first', 'player', 'one', 'point', 'mear']</td>\n",
       "      <td>first come player one point mear</td>\n",
       "      <td>['first', 'player', 'one', 'point', 'mear']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275850</td>\n",
       "      <td>3</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>If that doesn't prove this game is the biggest...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>if that do not prove this game be the big scam...</td>\n",
       "      <td>['if', 'that', 'do', 'not', 'prove', 'this', '...</td>\n",
       "      <td>['if', 'that', 'do', 'not', 'prove', 'this', '...</td>\n",
       "      <td>if that do not prove this game be the big scam...</td>\n",
       "      <td>['prove', 'this_game', 'big', 'scam', 'know']</td>\n",
       "      <td>prove big scam know</td>\n",
       "      <td>['prove', 'big', 'scam', 'know']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275850</td>\n",
       "      <td>4</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>The devs completely lied about countless featu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>the developer completely lie about countless f...</td>\n",
       "      <td>['the', 'developer', 'completely', 'lie', 'abo...</td>\n",
       "      <td>['the', 'developer', 'completely', 'lie', 'abo...</td>\n",
       "      <td>the developer completely lie about countless f...</td>\n",
       "      <td>['the_developer', 'completely', 'lie_about', '...</td>\n",
       "      <td>developer completely lie countless feature meant</td>\n",
       "      <td>['developer', 'completely', 'lie', 'countless'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275850</td>\n",
       "      <td>5</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>______________________________________________...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1</td>\n",
       "      <td>i clearly have very strong feel about the game...</td>\n",
       "      <td>['clearly', 'have', 'very', 'strong', 'feel', ...</td>\n",
       "      <td>['clearly', 'have', 'very', 'strong', 'feel', ...</td>\n",
       "      <td>clearly have very strong feel about the game a...</td>\n",
       "      <td>['clearly', 'strong', 'feel', 'play', 'hour', ...</td>\n",
       "      <td>clearly strong feel play hour hello games rele...</td>\n",
       "      <td>['clearly', 'strong', 'feel', 'play_hour', 'he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  index          name  \\\n",
       "0  275850      1  No Man's Sky   \n",
       "1  275850      2  No Man's Sky   \n",
       "2  275850      3  No Man's Sky   \n",
       "3  275850      4  No Man's Sky   \n",
       "4  275850      5  No Man's Sky   \n",
       "\n",
       "                                             content  \\\n",
       "0  This was my review prior to the 1.1 update ___...   \n",
       "1  This was my review prior to the 1.1 update ___...   \n",
       "2  This was my review prior to the 1.1 update ___...   \n",
       "3  This was my review prior to the 1.1 update ___...   \n",
       "4  This was my review prior to the 1.1 update ___...   \n",
       "\n",
       "                                            sentence  review_score  \\\n",
       "0  This was my review prior to the 1.1 update ___...             1   \n",
       "1  When the game first came out it had over 200,0...             1   \n",
       "2  If that doesn't prove this game is the biggest...             1   \n",
       "3  The devs completely lied about countless featu...             1   \n",
       "4  ______________________________________________...             1   \n",
       "\n",
       "   review_votes  readability  \\\n",
       "0             1         17.6   \n",
       "1             1          6.5   \n",
       "2             1          5.6   \n",
       "3             1          8.7   \n",
       "4             1         29.1   \n",
       "\n",
       "                                preprocessed_reviews  \\\n",
       "0  this be my review prior to the update nothis g...   \n",
       "1  when the game first come out it have over play...   \n",
       "2  if that do not prove this game be the big scam...   \n",
       "3  the developer completely lie about countless f...   \n",
       "4  i clearly have very strong feel about the game...   \n",
       "\n",
       "                                           wordtoken  \\\n",
       "0  ['this', 'be', 'my', 'review', 'prior', 'to', ...   \n",
       "1  ['when', 'the', 'game', 'first', 'come', 'out'...   \n",
       "2  ['if', 'that', 'do', 'not', 'prove', 'this', '...   \n",
       "3  ['the', 'developer', 'completely', 'lie', 'abo...   \n",
       "4  ['clearly', 'have', 'very', 'strong', 'feel', ...   \n",
       "\n",
       "                                      correctmapping  \\\n",
       "0  ['this', 'be', 'my', 'review', 'prior', 'to', ...   \n",
       "1  ['when', 'the', 'game', 'first', 'come', 'out'...   \n",
       "2  ['if', 'that', 'do', 'not', 'prove', 'this', '...   \n",
       "3  ['the', 'developer', 'completely', 'lie', 'abo...   \n",
       "4  ['clearly', 'have', 'very', 'strong', 'feel', ...   \n",
       "\n",
       "                                      ngrams_reviews  \\\n",
       "0  this be my review prior to the update nothin g...   \n",
       "1  when the game first come out it have over play...   \n",
       "2  if that do not prove this game be the big scam...   \n",
       "3  the developer completely lie about countless f...   \n",
       "4  clearly have very strong feel about the game a...   \n",
       "\n",
       "                                        ngrams_token  \\\n",
       "0  ['review', 'prior', 'update', 'nothin', 'fail'...   \n",
       "1        ['first', 'player', 'one', 'point', 'mear']   \n",
       "2      ['prove', 'this_game', 'big', 'scam', 'know']   \n",
       "3  ['the_developer', 'completely', 'lie_about', '...   \n",
       "4  ['clearly', 'strong', 'feel', 'play', 'hour', ...   \n",
       "\n",
       "                                         lda_reviews  \\\n",
       "0  review prior update nothin fail miserably anno...   \n",
       "1                   first come player one point mear   \n",
       "2                                prove big scam know   \n",
       "3   developer completely lie countless feature meant   \n",
       "4  clearly strong feel play hour hello games rele...   \n",
       "\n",
       "                                           lda_token  \n",
       "0  ['review', 'prior', 'update', 'nothin', 'fail'...  \n",
       "1        ['first', 'player', 'one', 'point', 'mear']  \n",
       "2                   ['prove', 'big', 'scam', 'know']  \n",
       "3  ['developer', 'completely', 'lie', 'countless'...  \n",
       "4  ['clearly', 'strong', 'feel', 'play_hour', 'he...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('D:\\Projects\\Jupyter\\Github Docs\\datasets\\preprocessed_word_correct_token.csv', error_bad_lines=False);\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f0a00bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 163847/163847 [00:00<00:00, 574380.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>sentence</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "      <th>readability</th>\n",
       "      <th>preprocessed_reviews</th>\n",
       "      <th>wordtoken</th>\n",
       "      <th>correctmapping</th>\n",
       "      <th>ngrams_reviews</th>\n",
       "      <th>ngrams_token</th>\n",
       "      <th>lda_reviews</th>\n",
       "      <th>lda_token</th>\n",
       "      <th>ngrams_token_nonsym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275850</td>\n",
       "      <td>1</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.6</td>\n",
       "      <td>this be my review prior to the update nothis g...</td>\n",
       "      <td>['this', 'be', 'my', 'review', 'prior', 'to', ...</td>\n",
       "      <td>['this', 'be', 'my', 'review', 'prior', 'to', ...</td>\n",
       "      <td>this be my review prior to the update nothin g...</td>\n",
       "      <td>['review', 'prior', 'update', 'nothin', 'fail'...</td>\n",
       "      <td>review prior update nothin fail miserably anno...</td>\n",
       "      <td>['review', 'prior', 'update', 'nothin', 'fail'...</td>\n",
       "      <td>review prior update nothin fail miserably anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275850</td>\n",
       "      <td>2</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>When the game first came out it had over 200,0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>when the game first come out it have over play...</td>\n",
       "      <td>['when', 'the', 'game', 'first', 'come', 'out'...</td>\n",
       "      <td>['when', 'the', 'game', 'first', 'come', 'out'...</td>\n",
       "      <td>when the game first come out it have over play...</td>\n",
       "      <td>['first', 'player', 'one', 'point', 'mear']</td>\n",
       "      <td>first come player one point mear</td>\n",
       "      <td>['first', 'player', 'one', 'point', 'mear']</td>\n",
       "      <td>first player one point mear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275850</td>\n",
       "      <td>3</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>If that doesn't prove this game is the biggest...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>if that do not prove this game be the big scam...</td>\n",
       "      <td>['if', 'that', 'do', 'not', 'prove', 'this', '...</td>\n",
       "      <td>['if', 'that', 'do', 'not', 'prove', 'this', '...</td>\n",
       "      <td>if that do not prove this game be the big scam...</td>\n",
       "      <td>['prove', 'this_game', 'big', 'scam', 'know']</td>\n",
       "      <td>prove big scam know</td>\n",
       "      <td>['prove', 'big', 'scam', 'know']</td>\n",
       "      <td>prove this_game big scam know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275850</td>\n",
       "      <td>4</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>The devs completely lied about countless featu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>the developer completely lie about countless f...</td>\n",
       "      <td>['the', 'developer', 'completely', 'lie', 'abo...</td>\n",
       "      <td>['the', 'developer', 'completely', 'lie', 'abo...</td>\n",
       "      <td>the developer completely lie about countless f...</td>\n",
       "      <td>['the_developer', 'completely', 'lie_about', '...</td>\n",
       "      <td>developer completely lie countless feature meant</td>\n",
       "      <td>['developer', 'completely', 'lie', 'countless'...</td>\n",
       "      <td>the_developer completely lie_about countless f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275850</td>\n",
       "      <td>5</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>______________________________________________...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1</td>\n",
       "      <td>i clearly have very strong feel about the game...</td>\n",
       "      <td>['clearly', 'have', 'very', 'strong', 'feel', ...</td>\n",
       "      <td>['clearly', 'have', 'very', 'strong', 'feel', ...</td>\n",
       "      <td>clearly have very strong feel about the game a...</td>\n",
       "      <td>['clearly', 'strong', 'feel', 'play', 'hour', ...</td>\n",
       "      <td>clearly strong feel play hour hello games rele...</td>\n",
       "      <td>['clearly', 'strong', 'feel', 'play_hour', 'he...</td>\n",
       "      <td>clearly strong feel play hour hello_games_have...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  index          name  \\\n",
       "0  275850      1  No Man's Sky   \n",
       "1  275850      2  No Man's Sky   \n",
       "2  275850      3  No Man's Sky   \n",
       "3  275850      4  No Man's Sky   \n",
       "4  275850      5  No Man's Sky   \n",
       "\n",
       "                                             content  \\\n",
       "0  This was my review prior to the 1.1 update ___...   \n",
       "1  This was my review prior to the 1.1 update ___...   \n",
       "2  This was my review prior to the 1.1 update ___...   \n",
       "3  This was my review prior to the 1.1 update ___...   \n",
       "4  This was my review prior to the 1.1 update ___...   \n",
       "\n",
       "                                            sentence  review_score  \\\n",
       "0  This was my review prior to the 1.1 update ___...             1   \n",
       "1  When the game first came out it had over 200,0...             1   \n",
       "2  If that doesn't prove this game is the biggest...             1   \n",
       "3  The devs completely lied about countless featu...             1   \n",
       "4  ______________________________________________...             1   \n",
       "\n",
       "   review_votes  readability  \\\n",
       "0             1         17.6   \n",
       "1             1          6.5   \n",
       "2             1          5.6   \n",
       "3             1          8.7   \n",
       "4             1         29.1   \n",
       "\n",
       "                                preprocessed_reviews  \\\n",
       "0  this be my review prior to the update nothis g...   \n",
       "1  when the game first come out it have over play...   \n",
       "2  if that do not prove this game be the big scam...   \n",
       "3  the developer completely lie about countless f...   \n",
       "4  i clearly have very strong feel about the game...   \n",
       "\n",
       "                                           wordtoken  \\\n",
       "0  ['this', 'be', 'my', 'review', 'prior', 'to', ...   \n",
       "1  ['when', 'the', 'game', 'first', 'come', 'out'...   \n",
       "2  ['if', 'that', 'do', 'not', 'prove', 'this', '...   \n",
       "3  ['the', 'developer', 'completely', 'lie', 'abo...   \n",
       "4  ['clearly', 'have', 'very', 'strong', 'feel', ...   \n",
       "\n",
       "                                      correctmapping  \\\n",
       "0  ['this', 'be', 'my', 'review', 'prior', 'to', ...   \n",
       "1  ['when', 'the', 'game', 'first', 'come', 'out'...   \n",
       "2  ['if', 'that', 'do', 'not', 'prove', 'this', '...   \n",
       "3  ['the', 'developer', 'completely', 'lie', 'abo...   \n",
       "4  ['clearly', 'have', 'very', 'strong', 'feel', ...   \n",
       "\n",
       "                                      ngrams_reviews  \\\n",
       "0  this be my review prior to the update nothin g...   \n",
       "1  when the game first come out it have over play...   \n",
       "2  if that do not prove this game be the big scam...   \n",
       "3  the developer completely lie about countless f...   \n",
       "4  clearly have very strong feel about the game a...   \n",
       "\n",
       "                                        ngrams_token  \\\n",
       "0  ['review', 'prior', 'update', 'nothin', 'fail'...   \n",
       "1        ['first', 'player', 'one', 'point', 'mear']   \n",
       "2      ['prove', 'this_game', 'big', 'scam', 'know']   \n",
       "3  ['the_developer', 'completely', 'lie_about', '...   \n",
       "4  ['clearly', 'strong', 'feel', 'play', 'hour', ...   \n",
       "\n",
       "                                         lda_reviews  \\\n",
       "0  review prior update nothin fail miserably anno...   \n",
       "1                   first come player one point mear   \n",
       "2                                prove big scam know   \n",
       "3   developer completely lie countless feature meant   \n",
       "4  clearly strong feel play hour hello games rele...   \n",
       "\n",
       "                                           lda_token  \\\n",
       "0  ['review', 'prior', 'update', 'nothin', 'fail'...   \n",
       "1        ['first', 'player', 'one', 'point', 'mear']   \n",
       "2                   ['prove', 'big', 'scam', 'know']   \n",
       "3  ['developer', 'completely', 'lie', 'countless'...   \n",
       "4  ['clearly', 'strong', 'feel', 'play_hour', 'he...   \n",
       "\n",
       "                                 ngrams_token_nonsym  \n",
       "0  review prior update nothin fail miserably anno...  \n",
       "1                        first player one point mear  \n",
       "2                      prove this_game big scam know  \n",
       "3  the_developer completely lie_about countless f...  \n",
       "4  clearly strong feel play hour hello_games_have...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_reviews = []\n",
    "for content in tqdm(data['ngrams_token']):\n",
    "    content=content.replace(\",\",\"\")\n",
    "    content=content.replace(\"'\",\"\")\n",
    "    content=content.replace(\"]\",\"\")\n",
    "    content=content.replace(\"[\",\"\")\n",
    "\n",
    "    preprocessed_reviews.append(content.strip())\n",
    "data['ngrams_token_nonsym']=preprocessed_reviews\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3967da30",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "344092ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=80, min_samples=40,\n",
    "                        prediction_data=True, gen_min_span_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8964d8cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stopwords = list(stopwords.words('english')) + ['and', 'the', 'game']\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    embedding_model=embedding_model,\n",
    "    vectorizer_model=CountVectorizer(ngram_range=(1, 2), stop_words=\"english\"),\n",
    "    top_n_words=10,\n",
    "    language='english',\n",
    "    calculate_probabilities=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d12c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sep= pd.read_csv('./processing_datasets/559650/processed559650_1.csv', encoding='utf-8')\n",
    "data_sep= data\n",
    "# preprocessed_reviews_sec = []\n",
    "# for sentance in tqdm(data_sep['correctmapping_nonsym']):\n",
    "# #     sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "#     sentance = re.sub('[^A-Za-z]+', ' ',  str(sentance))\n",
    "#     sentance = re.sub('\\W+', ' ', str(sentance))\n",
    "#     preprocessed_reviews_sec.append(sentance.strip())\n",
    "    \n",
    "    \n",
    "# data_sep['correctmapping_nonsym_2']=preprocessed_reviews_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33f07f85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8aa1d7066f48729c32e612a091253e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 14:15:11,003 - BERTopic - Transformed documents to Embeddings\n",
      "2023-10-10 14:19:51,795 - BERTopic - Reduced dimensionality\n",
      "2023-10-10 14:41:10,767 - BERTopic - Clustered reduced embeddings\n"
     ]
    }
   ],
   "source": [
    "docs = data_sep['ngrams_token_nonsym']\n",
    "\n",
    "#model.fit(data['selftext'])\n",
    "topics, probs = topic_model.fit_transform(data_sep['ngrams_token_nonsym'])\n",
    "\n",
    "# Reduce outliers\n",
    "new_topics = topic_model.reduce_outliers(docs, topics, probabilities=probs, strategy=\"probabilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddc8282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.update_topics(docs, topics=new_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "029a0f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.topics_ = new_topics\n",
    "documents = pd.DataFrame({\"Document\": docs, \"Topic\": new_topics})\n",
    "topic_model._update_topic_size(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6decf9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 1\n",
      "-1: 2\n",
      "-1: 3\n",
      "13: 4\n",
      "7: 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"{topics[i]}: {data_sep['index'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e829a802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5088</td>\n",
       "      <td>0_no_man_be_sky_no_mans_sky_no_man_sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3345</td>\n",
       "      <td>1_represent_ect_comin_onwards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3124</td>\n",
       "      <td>2_gtx_ram_amd_cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3042</td>\n",
       "      <td>3_refund_steam_get_refund_policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4639</td>\n",
       "      <td>4_planet_every_planet_each_planet_explore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>339</td>\n",
       "      <td>90</td>\n",
       "      <td>339_worth_pound_defnitely_this_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>340</td>\n",
       "      <td>348</td>\n",
       "      <td>340_land_on_asteroid_atmosphere_land_on_planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>341</td>\n",
       "      <td>207</td>\n",
       "      <td>341_regret_research_rip_turd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>342</td>\n",
       "      <td>181</td>\n",
       "      <td>342_hyperdrive_the_hyperdrive_drive_hyper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>343</td>\n",
       "      <td>306</td>\n",
       "      <td>343_run_smoothly_perfectly_run_fine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                            Name\n",
       "0        0   5088          0_no_man_be_sky_no_mans_sky_no_man_sky\n",
       "1        1   3345                   1_represent_ect_comin_onwards\n",
       "2        2   3124                               2_gtx_ram_amd_cpu\n",
       "3        3   3042                3_refund_steam_get_refund_policy\n",
       "4        4   4639       4_planet_every_planet_each_planet_explore\n",
       "..     ...    ...                                             ...\n",
       "339    339     90             339_worth_pound_defnitely_this_game\n",
       "340    340    348  340_land_on_asteroid_atmosphere_land_on_planet\n",
       "341    341    207                    341_regret_research_rip_turd\n",
       "342    342    181       342_hyperdrive_the_hyperdrive_drive_hyper\n",
       "343    343    306             343_run_smoothly_perfectly_run_fine\n",
       "\n",
       "[344 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = topic_model.get_topic_info(); freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1105be29",
   "metadata": {},
   "source": [
    "## Reduce topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d8ba93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 14:41:25,804 - BERTopic - Reduced number of topics from 344 to 263\n"
     ]
    }
   ],
   "source": [
    "topic_model.reduce_topics(docs, nr_topics=\"auto\")\n",
    "topics = topic_model.topics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0f12deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8220</td>\n",
       "      <td>0_ship_fly_pirate_alien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6233</td>\n",
       "      <td>1_exploration_explore_survival_space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5088</td>\n",
       "      <td>2_no_man_be_sky_no_mans_sky_no_man_sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4639</td>\n",
       "      <td>3_planet_every_planet_explore_each_planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4313</td>\n",
       "      <td>4_play_this_game_love_played</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>258</td>\n",
       "      <td>93</td>\n",
       "      <td>258_scratch_the_surface_the_surface_of_barely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>92</td>\n",
       "      <td>259_pro_outweigh_proteus_pros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>84</td>\n",
       "      <td>260_moment_onwards_action_wierd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>261</td>\n",
       "      <td>83</td>\n",
       "      <td>261_work_fine_for_me_work_fine_fine_for_me_jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>262</td>\n",
       "      <td>81</td>\n",
       "      <td>262_explorer_type_pure_andreas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                               Name\n",
       "0        0   8220                            0_ship_fly_pirate_alien\n",
       "1        1   6233               1_exploration_explore_survival_space\n",
       "2        2   5088             2_no_man_be_sky_no_mans_sky_no_man_sky\n",
       "3        3   4639          3_planet_every_planet_explore_each_planet\n",
       "4        4   4313                       4_play_this_game_love_played\n",
       "..     ...    ...                                                ...\n",
       "258    258     93      258_scratch_the_surface_the_surface_of_barely\n",
       "259    259     92                      259_pro_outweigh_proteus_pros\n",
       "260    260     84                    260_moment_onwards_action_wierd\n",
       "261    261     83  261_work_fine_for_me_work_fine_fine_for_me_jus...\n",
       "262    262     81                     262_explorer_type_pure_andreas\n",
       "\n",
       "[263 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = topic_model.get_topic_info(); freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de733100",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3cfb81b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "topic_model.save(\"./results/BERTopic_trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6a53577",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.to_csv('./results/freq-BERTopic_model.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ecec0f",
   "metadata": {},
   "source": [
    "## Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3866f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Documents\n",
    "documents = pd.DataFrame({\"Document\": docs,\n",
    "                          \"content\":data_sep['content'],\n",
    "                          \"sent_content\":data_sep['sentence'],\n",
    "                          \"id\":data_sep['index'],\n",
    "                          \"ID\": range(len(docs)),\n",
    "                          \"Topic\": new_topics})\n",
    "documents_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})\n",
    "cleaned_docs = topic_model._preprocess_text(documents_per_topic.Document.values)\n",
    "\n",
    "# Extract vectorizer and analyzer from BERTopic\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "# Extract features for Topic Coherence evaluation\n",
    "words = vectorizer.get_feature_names()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "               for topic in range(len(set(topics))-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc1741fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.to_csv('./results/documents.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d54ff",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5941ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic.load(\"./results/BERTopic_trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cc268bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8220</td>\n",
       "      <td>0_ship_fly_pirate_alien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6233</td>\n",
       "      <td>1_exploration_explore_survival_space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5088</td>\n",
       "      <td>2_no_man_be_sky_no_mans_sky_no_man_sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4639</td>\n",
       "      <td>3_planet_every_planet_explore_each_planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4313</td>\n",
       "      <td>4_play_this_game_love_played</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>258</td>\n",
       "      <td>93</td>\n",
       "      <td>258_scratch_the_surface_the_surface_of_barely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>92</td>\n",
       "      <td>259_pro_outweigh_proteus_pros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>84</td>\n",
       "      <td>260_moment_onwards_action_wierd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>261</td>\n",
       "      <td>83</td>\n",
       "      <td>261_work_fine_for_me_work_fine_fine_for_me_jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>262</td>\n",
       "      <td>81</td>\n",
       "      <td>262_explorer_type_pure_andreas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                               Name\n",
       "0        0   8220                            0_ship_fly_pirate_alien\n",
       "1        1   6233               1_exploration_explore_survival_space\n",
       "2        2   5088             2_no_man_be_sky_no_mans_sky_no_man_sky\n",
       "3        3   4639          3_planet_every_planet_explore_each_planet\n",
       "4        4   4313                       4_play_this_game_love_played\n",
       "..     ...    ...                                                ...\n",
       "258    258     93      258_scratch_the_surface_the_surface_of_barely\n",
       "259    259     92                      259_pro_outweigh_proteus_pros\n",
       "260    260     84                    260_moment_onwards_action_wierd\n",
       "261    261     83  261_work_fine_for_me_work_fine_fine_for_me_jus...\n",
       "262    262     81                     262_explorer_type_pure_andreas\n",
       "\n",
       "[263 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = topic_model.get_topic_info(); freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8202fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topic_model.topics_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8b5c2",
   "metadata": {},
   "source": [
    "# Evaluation (coherence score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a3e77",
   "metadata": {},
   "source": [
    "## c_npmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55f7edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_npmi = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_npmi')\n",
    "coherence_npmi = coherence_model_npmi.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35d9f287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.11698866538503871\n"
     ]
    }
   ],
   "source": [
    "print('\\nCoherence Score: ', coherence_npmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb601a",
   "metadata": {},
   "source": [
    "## c_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d5f9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_cv = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_v')\n",
    "coherence_cv = coherence_model_cv.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02f27109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.6361733872804923\n"
     ]
    }
   ],
   "source": [
    "print('\\nCoherence Score: ', coherence_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f87d88",
   "metadata": {},
   "source": [
    "## u_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf21720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_u_mass = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='u_mass')\n",
    "coherence_u_mass = coherence_model_u_mass.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cfad32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  -1.1270547395581239\n"
     ]
    }
   ],
   "source": [
    "print('\\nCoherence Score: ', coherence_u_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fcc75",
   "metadata": {},
   "source": [
    "## c_uci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f50571e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_c_uci = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_uci')\n",
    "coherence_c_uci = coherence_model_c_uci.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2de8eb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.11493633304132984\n"
     ]
    }
   ],
   "source": [
    "print('\\nCoherence Score: ', coherence_c_uci)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "255px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
